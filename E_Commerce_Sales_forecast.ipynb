{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool, MetricVisualizer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import boxcox\n",
    "import warnings\n",
    "import shap\n",
    "import GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, encoding=\"ISO-8859-1\", dtype={'CustomerID': str})\n",
    "    data[\"InvoiceDate\"] = pd.to_datetime(data.InvoiceDate, cache=True)\n",
    "    data = data[data.UnitPrice > 0]\n",
    "    data = data[(data.Quantity > 0) & (data.Quantity < 55)]\n",
    "    data[\"Revenue\"] = data.Quantity * data.UnitPrice\n",
    "    data[\"Year\"] = data.InvoiceDate.dt.year\n",
    "    data[\"Quarter\"] = data.InvoiceDate.dt.quarter\n",
    "    data[\"Month\"] = data.InvoiceDate.dt.month\n",
    "    data[\"Week\"] = data.InvoiceDate.dt.isocalendar().week\n",
    "    data[\"Weekday\"] = data.InvoiceDate.dt.weekday\n",
    "    data[\"Day\"] = data.InvoiceDate.dt.day\n",
    "    data[\"Dayofyear\"] = data.InvoiceDate.dt.dayofyear\n",
    "    data[\"Date\"] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n",
    "    data = data.dropna(subset=[\"CustomerID\", \"Description\"])\n",
    "    data[\"Description\"] = data[\"Description\"].str.lower()\n",
    "    data = data[~data[\"Description\"].str.contains(\"nan\")]\n",
    "    data = data[data.Description.str.len() > 0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and visualize stock codes\n",
    "def analyze_stock_codes(data):\n",
    "    data[\"StockCodeLength\"] = data.StockCode.str.len()\n",
    "    data[\"nNumericStockCode\"] = data.StockCode.apply(lambda l: sum(1 for c in l if c.isdigit()))\n",
    "    data = data[(data.nNumericStockCode == 5) & (data.StockCodeLength == 5)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster products\n",
    "def cluster_products(data, n_clusters=30):\n",
    "    products = pd.DataFrame(index=data.StockCode.unique(), columns=[\"MedianPrice\", \"MedianQuantities\", \"Customers\", \"DescriptionLength\"])\n",
    "    products[\"MedianPrice\"] = data.groupby(\"StockCode\").UnitPrice.median()\n",
    "    products[\"MedianQuantities\"] = data.groupby(\"StockCode\").Quantity.median()\n",
    "    products[\"Customers\"] = data.groupby(\"StockCode\").CustomerID.nunique()\n",
    "    products[\"DescriptionLength\"] = data.groupby(\"StockCode\").Description.apply(lambda x: x.str.len().median())\n",
    "    \n",
    "    for col in products.columns:\n",
    "        products[col] = boxcox(products[col])[0]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(products.values)\n",
    "    km = KMeans(n_clusters=n_clusters)\n",
    "    products[\"cluster\"] = km.fit_predict(X)\n",
    "    \n",
    "    data[\"ProductType\"] = data.StockCode.map(products.cluster)\n",
    "    return data, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily data\n",
    "def aggregate_daily_data(data):\n",
    "    grouped_features = [\"Date\", \"Year\", \"Quarter\", \"Month\", \"Week\", \"Weekday\", \"Dayofyear\", \"Day\", \"StockCode\"]\n",
    "    daily_data = data.groupby(grouped_features).agg({\"Quantity\": \"sum\", \"Revenue\": \"sum\"}).reset_index()\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and validation data\n",
    "def prepare_data(daily_data, week):\n",
    "    X = daily_data.drop([\"Quantity\", \"Revenue\", \"Date\"], axis=1)\n",
    "    y = np.log(daily_data[\"Quantity\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CatBoost model class\n",
    "class CatHyperparameter:\n",
    "    def __init__(self, loss=\"RMSE\", metric=\"RMSE\", iterations=1000, max_depth=4, l2_leaf_reg=3, seed=0):\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.max_depth = max_depth\n",
    "        self.l2_leaf_reg = l2_leaf_reg\n",
    "        self.iterations = iterations\n",
    "        self.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CatBoost model class (keep the rest of the class as before)\n",
    "class Catmodel:\n",
    "    def __init__(self, name, params):\n",
    "        self.name = name\n",
    "        self.params = params\n",
    "\n",
    "    def set_data(self, X, y, week):\n",
    "        cat_features_idx = np.where(X.dtypes != float)[0]\n",
    "        x_train, self.x_val = X[X.Week < week], X[X.Week >= week]\n",
    "        y_train, self.y_val = y[X.Week < week], y[X.Week >= week]\n",
    "        self.train_pool = Pool(x_train, y_train, cat_features=cat_features_idx)\n",
    "        self.val_pool = Pool(self.x_val, self.y_val, cat_features=cat_features_idx)\n",
    "\n",
    "    def prepare_model(self):\n",
    "        self.model = CatBoostRegressor(\n",
    "            loss_function=self.params.loss,\n",
    "            random_seed=self.params.seed,\n",
    "            logging_level='Silent',\n",
    "            iterations=self.params.iterations,\n",
    "            max_depth=self.params.max_depth,\n",
    "            l2_leaf_reg=self.params.l2_leaf_reg,\n",
    "            od_type='Iter',\n",
    "            od_wait=40,\n",
    "            train_dir=self.name,\n",
    "            has_time=True\n",
    "        )\n",
    "\n",
    "    def learn(self, plot=False):\n",
    "        self.prepare_model()\n",
    "        self.model.fit(self.train_pool, eval_set=self.val_pool, plot=plot)\n",
    "        print(f\"{self.name}, early-stopped model tree count {self.model.tree_count_}\")\n",
    "\n",
    "    def score(self):\n",
    "        return self.model.score(self.val_pool)\n",
    "\n",
    "    def show_importances(self, kind=\"bar\"):\n",
    "        explainer = shap.TreeExplainer(self.model)\n",
    "        shap_values = explainer.shap_values(self.val_pool)\n",
    "        if kind == \"bar\":\n",
    "            return shap.summary_plot(shap_values, self.x_val, plot_type=\"bar\")\n",
    "        return shap.summary_plot(shap_values, self.x_val)\n",
    "\n",
    "    def get_val_results(self):\n",
    "        self.results = pd.DataFrame(self.y_val)\n",
    "        self.results[\"prediction\"] = self.predict(self.x_val)\n",
    "        self.results[\"error\"] = np.abs(self.results[self.results.columns.values[0]].values - self.results.prediction)\n",
    "        self.results[\"Month\"] = self.x_val.Month\n",
    "        self.results[\"SquaredError\"] = self.results.error.apply(lambda l: np.power(l, 2))\n",
    "\n",
    "    def show_val_results(self):\n",
    "        self.get_val_results()\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "        sns.distplot(self.results.error, ax=ax[0])\n",
    "        ax[0].set_xlabel(\"Single absolute error\")\n",
    "        ax[0].set_ylabel(\"Density\")\n",
    "        self.median_absolute_error = np.median(self.results.error)\n",
    "        print(f\"Median absolute error: {self.median_absolute_error}\")\n",
    "        ax[0].axvline(self.median_absolute_error, c=\"black\")\n",
    "        ax[1].scatter(self.results.prediction.values, self.results[self.results.columns[0]].values, c=self.results.error, cmap=\"RdYlBu_r\", s=1)\n",
    "        ax[1].set_xlabel(\"Prediction\")\n",
    "        ax[1].set_ylabel(\"Target\")\n",
    "        return ax\n",
    "\n",
    "    def get_monthly_RMSE(self):\n",
    "        return self.results.groupby(\"Month\").SquaredError.mean().apply(lambda l: np.sqrt(l))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def get_dependence_plot(self, feature1, feature2=None):\n",
    "        explainer = shap.TreeExplainer(self.model)\n",
    "        shap_values = explainer.shap_values(self.val_pool)\n",
    "        if feature2 is None:\n",
    "            return shap.dependence_plot(feature1, shap_values, self.x_val)\n",
    "        else:\n",
    "            return shap.dependence_plot(feature1, shap_values, self.x_val, interaction_index=feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter tuning class\n",
    "class Hypertuner:\n",
    "    def __init__(self, model, max_iter=10, max_time=10, max_depth=6, max_l2_leaf_reg=20):\n",
    "        self.bounds = [{'name': 'depth', 'type': 'discrete', 'domain': (1, max_depth)},\n",
    "                       {'name': 'l2_leaf_reg', 'type': 'discrete', 'domain': (1, max_l2_leaf_reg)}]\n",
    "        self.model = model\n",
    "        self.max_iter = max_iter\n",
    "        self.max_time = max_time\n",
    "        self.best_depth = None\n",
    "        self.best_l2_leaf_reg = None\n",
    "\n",
    "    def objective(self, params):\n",
    "        params = params[0]\n",
    "        params = CatHyperparameter(max_depth=params[0], l2_leaf_reg=params[1])\n",
    "        self.model.params = params\n",
    "        self.model.learn()\n",
    "        return self.model.score()\n",
    "\n",
    "    def learn(self):\n",
    "        np.random.seed(777)\n",
    "        optimizer = GPyOpt.methods.BayesianOptimization(f=self.objective, domain=self.bounds, acquisition_type='EI', acquisition_par=0.2, exact_eval=True)\n",
    "        optimizer.run_optimization(self.max_iter, self.max_time)\n",
    "        optimizer.plot_convergence()\n",
    "        best = optimizer.X[np.argmin(optimizer.Y)]\n",
    "        self.best_depth = best[0]\n",
    "        self.best_l2_leaf_reg = best[1]\n",
    "        print(f\"Optimal depth is {self.best_depth} and optimal l2-leaf-reg is {self.best_l2_leaf_reg}\")\n",
    "        print('Optimal RMSE:', np.min(optimizer.Y))\n",
    "\n",
    "    def retrain_catmodel(self):\n",
    "        params = CatHyperparameter(max_depth=self.best_depth, l2_leaf_reg=self.best_l2_leaf_reg)\n",
    "        self.model.params = params\n",
    "        self.model.learn(plot=True)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main function to run the workflow\n",
    "def main():\n",
    "    data = load_data(\"data.csv\")\n",
    "    data = analyze_stock_codes(data)\n",
    "    data, products = cluster_products(data)\n",
    "    daily_data = aggregate_daily_data(data)\n",
    "    week = daily_data.Week.max() - 2\n",
    "    X, y = prepare_data(daily_data, week)\n",
    "    \n",
    "    params = CatHyperparameter()\n",
    "    model = Catmodel(\"baseline\", params)\n",
    "    model.set_data(X, y, week)\n",
    "    model.learn(plot=True)\n",
    "    model.score()\n",
    "    model.show_val_results()\n",
    "    model.show_importances()\n",
    "    model.show_importances(kind=None)\n",
    "    np.mean(np.abs(np.exp(model.results.prediction) - np.exp(model.results.Quantity)))\n",
    "    np.median(np.abs(np.exp(model.results.prediction) - np.exp(model.results.Quantity)))\n",
    "\n",
    "    search = Hypertuner(model)\n",
    "    search.learn()\n",
    "    search.retrain_catmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
